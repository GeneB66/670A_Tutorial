{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Barnes, R. \"Gene\"</font> - <font color='purple'><u>HW Individual Tutorial: Image Classification</u></font> - 3/16/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>K-State Honor Code:</font> \"On my honor, as a student, I have neither given nor received unauthorized aid on this academic work.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In our current society, we are continually looking to improve security.\n",
    "- Security is in many forms, cybersecurity (cryptography, servers, Internet), physical (access control, video survelliance, biometrics). We as humans have a need to improve on these as time progresses. In the past few years, and even the last several months, there have been incidents both on campus and across the nation that is fueling an urgency to improve security. \n",
    "- As I work with our security team in Housing and Dining Services, we too see a great need to improve our security for our residential students. Aside from upgrading an outdated video survelliance system, what if we were able to use Image Classification with our video survelliance to distinquish student, faculty and staff from those who aren't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Deep Learning and Convolutional Neural Networks (CNNs).\n",
    "- First, what is \"deep learning\"? \"Deep learning is a type of machine learning in which a model learns to\n",
    "perform classification tasks directly from images, text, or sound. Deep\n",
    "learning is usually implemented using a neural network architecture. The\n",
    "term “deep” refers to the number of layers in the network—the more layers,\n",
    "the deeper the network. Traditional neural networks contain only 2 or 3\n",
    "layers, while deep networks can have hundreds.\"\n",
    "- From https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/d/80879v00_Deep_Learning_ebook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, what is a CNN? \"A convolutional neural network (CNN, or ConvNet) is one of the\n",
    "most popular algorithms for deep learning with images and video.\n",
    "Like other neural networks, a CNN is composed of an input layer,\n",
    "an output layer, and many hidden layers in between.\n",
    "Feature Detection Layers\n",
    "These layers perform one of three types of operations on the data:\n",
    "convolution, pooling, or rectified linear unit (ReLU).\n",
    "Convolution puts the input images through a set of convolutional\n",
    "filters, each of which activates certain features from the images.\n",
    "Pooling simplifies the output by performing nonlinear\n",
    "downsampling, reducing the number of parameters that the\n",
    "network needs to learn about.\n",
    "Rectified linear unit (ReLU) allows for faster and more effective\n",
    "training by mapping negative values to zero and maintaining\n",
    "positive values.\n",
    "These three operations are repeated over tens or hundreds of\n",
    "layers, with each layer learning to detect different features.\"\n",
    "- From https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/d/80879v00_Deep_Learning_ebook.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Python library imgaug\n",
    "- This library helps you with augmenting images for your machine learning projects. It converts a set of input images into a new, much larger set of slightly altered images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is our goal?\n",
    "- What we are looking at with this deep learning and the CNNs is taking images and using both, process the images by various means and sequences to ensure greater accuraccy with image classification.\n",
    "- These sequences are how we get the process to see all parts of an image so that even one pixel or group of pixels may be used to determine a cat from a dog, or in our grand scheme, a residential student from staff. This could be anything from flipping images to blurring them, all to help increase the recognition and accuracy of one image from another.\n",
    "- To meet our goal, or our example, we need to \n",
    " 1. Show how to use imgaug (Image Augmentation) sequence to help with determining images. \n",
    " 2. Show results of the examples. \n",
    " 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Python 2.7 coding for machine learning using imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coding below here courtesy of https://github.com/aleju/imgaug\n",
    "- Here this example shows an augmentation sequence that might be useful for many common experiments. It applies crops and affine transformations to images, flips some of the images horizontally, adds a bit of noise and blur and also changes the contrast as well as brightness. (http://imgaug.readthedocs.io/en/latest/source/examples_basics.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "# random example images\n",
    "images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "# Define our sequence of augmentation steps that will be applied to every image\n",
    "# All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "# in 50% of all cases. In all other cases they will sample new values\n",
    "# _per channel_.\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "        # crop images by -5% to 10% of their height/width\n",
    "        sometimes(iaa.CropAndPad(\n",
    "            percent=(-0.05, 0.1),\n",
    "            pad_mode=ia.ALL,\n",
    "            pad_cval=(0, 255)\n",
    "        )),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )),\n",
    "        # execute 0 to 5 of the following (less important) augmenters per image\n",
    "        # don't execute all of them, as that would often be way too strong\n",
    "        iaa.SomeOf((0, 5),\n",
    "            [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                # search either for all edges or for directed edges,\n",
    "                # blend the result with the original image using a blobby mask\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "                # either change the brightness of the whole image (sometimes\n",
    "                # per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-4, 0),\n",
    "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                        second=iaa.ContrastNormalization((0.5, 2.0))\n",
    "                    )\n",
    "                ]),\n",
    "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "images_aug = seq.augment_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Quickly show example results of your augmentation sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not execute image viewer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8851aeb282b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# show an image with 8*8 augmented versions of image 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Show an image with 8*8 augmented versions of image 0 and 8*8 augmented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gene\\Anaconda2\\lib\\site-packages\\imgaug\\augmenters\\meta.pyc\u001b[0m in \u001b[0;36mshow_grid\u001b[1;34m(self, images, rows, cols)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \"\"\"\n\u001b[0;32m    761\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_deterministic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gene\\Anaconda2\\lib\\site-packages\\numpy\\lib\\utils.pyc\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gene\\Anaconda2\\lib\\site-packages\\scipy\\misc\\pilutil.pyc\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not execute image viewer.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not execute image viewer."
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
    "seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.GaussianBlur((0, 3.0))])\n",
    "\n",
    "# show an image with 8*8 augmented versions of image 0\n",
    "seq.show_grid(images[0], cols=8, rows=8)\n",
    "\n",
    "# Show an image with 8*8 augmented versions of image 0 and 8*8 augmented\n",
    "# versions of image 1. The identical augmentations will be applied to\n",
    "# image 0 and 1.\n",
    "seq.show_grid([images[0], images[1]], cols=8, rows=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
